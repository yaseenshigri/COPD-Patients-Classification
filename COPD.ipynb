{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa5e3cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2900\n",
      "60\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler  #library to normalize\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score, auc, precision_recall_curve, roc_curve\n",
    "from sklearn.linear_model import LogisticRegression   \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd                     \n",
    "import numpy as np                      \n",
    "import seaborn as sns                   \n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "df=pd.read_csv('D:/Desktop/machine learning/COPD dataset.csv')\n",
    "nRow, nCol = df.shape                \n",
    "print(nRow)\n",
    "print(nCol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d76dff2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>SBP</th>\n",
       "      <th>DBP</th>\n",
       "      <th>Pulse</th>\n",
       "      <th>Tx_y</th>\n",
       "      <th>PHA</th>\n",
       "      <th>AirPollution</th>\n",
       "      <th>DS</th>\n",
       "      <th>SPY</th>\n",
       "      <th>F_DBT</th>\n",
       "      <th>...</th>\n",
       "      <th>BDR2_FEF_Base</th>\n",
       "      <th>DLCO</th>\n",
       "      <th>DC_DLCO_pcForecast</th>\n",
       "      <th>DC_DLVA_Measure</th>\n",
       "      <th>DC_DLVA_pcForecast</th>\n",
       "      <th>LABA</th>\n",
       "      <th>LAMA</th>\n",
       "      <th>ICS_LABA</th>\n",
       "      <th>Methylxanthine_YN</th>\n",
       "      <th>target_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.2</td>\n",
       "      <td>80.0</td>\n",
       "      <td>4.01</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2895</th>\n",
       "      <td>1.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>2.95</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2896</th>\n",
       "      <td>1.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>49.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2897</th>\n",
       "      <td>1.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>11.2</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2.75</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2898</th>\n",
       "      <td>1.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.84</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2899</th>\n",
       "      <td>1.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>8.9</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2.45</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2900 rows Ã— 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sex    SBP   DBP  Pulse  Tx_y  PHA  AirPollution    DS   SPY  F_DBT  \\\n",
       "0     1.0  120.0  70.0   78.0  16.0  1.0           0.0  20.0   4.0    0.0   \n",
       "1     2.0  103.0  70.0   78.0   1.0  0.0           0.0  51.0  51.0    1.0   \n",
       "2     1.0    NaN   NaN    NaN   1.0  0.0           0.0   NaN   NaN    0.0   \n",
       "3     2.0    NaN   NaN    NaN   4.0  0.0           0.0   NaN   NaN    0.0   \n",
       "4     1.0    NaN   NaN    NaN   1.0  0.0           0.0  45.0  45.0    0.0   \n",
       "...   ...    ...   ...    ...   ...  ...           ...   ...   ...    ...   \n",
       "2895  1.0  110.0  70.0   85.0   8.0  0.0           0.0  23.0  23.0    0.0   \n",
       "2896  1.0  136.0  71.0   82.0   NaN  0.0           0.0  27.0  41.0    1.0   \n",
       "2897  1.0  104.0  56.0   66.0   3.0  NaN           1.0   NaN   NaN    0.0   \n",
       "2898  1.0  128.0  74.0   78.0   0.0  0.0           1.0  42.0  42.0    0.0   \n",
       "2899  1.0  110.0  70.0  120.0  22.0  1.0           1.0  42.0  21.0    0.0   \n",
       "\n",
       "      ...  BDR2_FEF_Base  DLCO  DC_DLCO_pcForecast  DC_DLVA_Measure  \\\n",
       "0     ...            NaN   NaN                 NaN              NaN   \n",
       "1     ...           14.0  14.2                80.0             4.01   \n",
       "2     ...           20.0   NaN                 NaN              NaN   \n",
       "3     ...            NaN   NaN                 NaN              NaN   \n",
       "4     ...           17.0   NaN                 NaN              NaN   \n",
       "...   ...            ...   ...                 ...              ...   \n",
       "2895  ...            5.0   5.0                31.0             2.95   \n",
       "2896  ...           49.0   NaN                 NaN              NaN   \n",
       "2897  ...          -17.0  11.2                64.0             2.75   \n",
       "2898  ...           32.0   6.0                38.0             1.84   \n",
       "2899  ...           -2.0   8.9                45.0             2.45   \n",
       "\n",
       "      DC_DLVA_pcForecast  LABA  LAMA  ICS_LABA  Methylxanthine_YN  \\\n",
       "0                    NaN   NaN   NaN       NaN                NaN   \n",
       "1                   75.0   0.0   0.0       1.0                0.0   \n",
       "2                    NaN   0.0   0.0       1.0                0.0   \n",
       "3                    NaN   0.0   0.0       1.0                0.0   \n",
       "4                    NaN   1.0   0.0       0.0                0.0   \n",
       "...                  ...   ...   ...       ...                ...   \n",
       "2895                82.0   0.0   0.0       1.0                NaN   \n",
       "2896                 NaN   0.0   1.0       1.0                1.0   \n",
       "2897                80.0   0.0   1.0       0.0                0.0   \n",
       "2898                47.0   0.0   1.0       1.0                0.0   \n",
       "2899                63.0   1.0   1.0       0.0                0.0   \n",
       "\n",
       "      target_value  \n",
       "0                0  \n",
       "1                0  \n",
       "2                0  \n",
       "3                0  \n",
       "4                0  \n",
       "...            ...  \n",
       "2895             1  \n",
       "2896             1  \n",
       "2897             1  \n",
       "2898             1  \n",
       "2899             1  \n",
       "\n",
       "[2900 rows x 60 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20f67264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2327\n",
       "1     573\n",
       "Name: target_value, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target_value'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1ef35f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Frequency')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.value_counts(df['target_value']).plot.bar()\n",
    "plt.title('Fraud class histogram')\n",
    "plt.xlabel('target_value')\n",
    "plt.ylabel('Frequency')\n",
    "# df['target_valuess'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "967b1c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5dcdfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop('target_value',axis=1)\n",
    "y=df['target_value'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9955456c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0\n",
      "1       0\n",
      "2       0\n",
      "3       0\n",
      "4       0\n",
      "       ..\n",
      "2895    1\n",
      "2896    1\n",
      "2897    1\n",
      "2898    1\n",
      "2899    1\n",
      "Name: target_value, Length: 2900, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf28ec35",
   "metadata": {},
   "source": [
    "# Filled the missing values using means strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "086b1e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer                                                                                                                          \n",
    "imputer = SimpleImputer(missing_values = np.nan, strategy = 'mean')\n",
    "imputer = imputer.fit(X)\n",
    "X_1 = imputer.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52743a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U imbalanced-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c616e1",
   "metadata": {},
   "source": [
    "### Balance the Data using SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3ad4431",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "oversample = SMOTE()\n",
    "X_1, y = oversample.fit_resample(X_1, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c98cbb9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2327\n",
       "1    2327\n",
       "Name: target_value, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "811e1518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4654, 59)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb8620ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Frequency')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y.value_counts().plot.bar()\n",
    "plt.title('Target_value histogram')\n",
    "plt.xlabel('y')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357377f8",
   "metadata": {},
   "source": [
    "# Feature selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16903156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# model =RandomForestClassifier(max_depth=1) \n",
    "# from boruta import BorutaPy\n",
    "# feat_selector = BorutaPy(model, n_estimators='auto', verbose=1, random_state=101)\n",
    "# feat_selector.fit(X_1,y)\n",
    "# print(feat_selector.support_) \n",
    "# print(feat_selector.ranking_) \n",
    "# X_filtered1 = feat_selector.transform(X_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c9f6792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_filtered1 .shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5eea96",
   "metadata": {},
   "source": [
    "# Normalized the whole selected features using MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "97f46527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final_selected=X_filtered1\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))                        \n",
    "X= scaler.fit_transform(X_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2013de0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4654, 59)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc540093",
   "metadata": {},
   "source": [
    "#  Divided the whole dataset into training and testing by keeping test size 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "405c408c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training features = (3723, 59)\n",
      "testing features = (3723,)\n",
      "training labels= (931, 59)\n",
      "testing labels = (931,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test,y_train, y_test = train_test_split(X,y, test_size=0.20,random_state=9)\n",
    "print('training features =',X_train.shape)\n",
    "print('testing features =',y_train.shape)\n",
    "print('training labels=',X_test.shape)\n",
    "print('testing labels =',y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8854e08d",
   "metadata": {},
   "source": [
    "# Random Forest (RF) Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f0a01efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.93      0.91       475\n",
      "           1       0.92      0.89      0.91       456\n",
      "\n",
      "    accuracy                           0.91       931\n",
      "   macro avg       0.91      0.91      0.91       931\n",
      "weighted avg       0.91      0.91      0.91       931\n",
      "\n",
      "0.9087003222341569\n",
      "[[441  34]\n",
      " [ 51 405]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "Rfc = RandomForestClassifier(n_estimators=100)       \n",
    "Rfc.fit(X_train, y_train)\n",
    "prediction = Rfc.predict(X_test)\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "print(classification_report(y_test, prediction))\n",
    "print(accuracy_score(y_test, prediction))\n",
    "print(confusion_matrix(y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "663a35e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "cm = confusion_matrix(y_test, predictions, labels=model.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                             display_labels=model.classes_)\n",
    "disp.plot()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15dc376",
   "metadata": {},
   "source": [
    "# Support Vector Machine (SVM) Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f1fc9e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.83      0.84       475\n",
      "           1       0.83      0.84      0.83       456\n",
      "\n",
      "    accuracy                           0.83       931\n",
      "   macro avg       0.83      0.83      0.83       931\n",
      "weighted avg       0.83      0.83      0.83       931\n",
      "\n",
      "0.8335123523093448\n",
      "[[395  80]\n",
      " [ 75 381]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "# model = svm.LinearSVC(multi_class=\"ovr\")\n",
    "Svm = svm.SVC()\n",
    "Svm.fit(X_train, y_train)\n",
    "prediction = Svm.predict(X_test)\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "print(classification_report(y_test, prediction))\n",
    "print(accuracy_score(y_test, prediction))\n",
    "print(confusion_matrix(y_test, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49d698d",
   "metadata": {},
   "source": [
    "# Decision Tree (DT) Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "af83cb3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.79      0.81       475\n",
      "           1       0.79      0.83      0.81       456\n",
      "\n",
      "    accuracy                           0.81       931\n",
      "   macro avg       0.81      0.81      0.81       931\n",
      "weighted avg       0.81      0.81      0.81       931\n",
      "\n",
      "0.8098818474758325\n",
      "[[375 100]\n",
      " [ 77 379]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "DT = DecisionTreeClassifier()\n",
    "DT.fit(X_train, y_train)\n",
    "prediction = DT.predict(X_test)\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "print(classification_report(y_test, prediction))\n",
    "print(accuracy_score(y_test, prediction))\n",
    "print(confusion_matrix(y_test, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2342cbd4",
   "metadata": {},
   "source": [
    "# Gradient Boosting  (GB) Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ebfb9cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89       475\n",
      "           1       0.91      0.84      0.87       456\n",
      "\n",
      "    accuracy                           0.88       931\n",
      "   macro avg       0.88      0.88      0.88       931\n",
      "weighted avg       0.88      0.88      0.88       931\n",
      "\n",
      "0.8796992481203008\n",
      "[[435  40]\n",
      " [ 72 384]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "GB = GradientBoostingClassifier(random_state=101)\n",
    "GB.fit(X_train, y_train)\n",
    "prediction = GB.predict(X_test)\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "print(classification_report(y_test, prediction))\n",
    "print(accuracy_score(y_test, prediction))\n",
    "print(confusion_matrix(y_test, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f3fb5d",
   "metadata": {},
   "source": [
    "# K nearest Neighbor (KNN) Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1de670b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.83      0.86       475\n",
      "           1       0.84      0.89      0.86       456\n",
      "\n",
      "    accuracy                           0.86       931\n",
      "   macro avg       0.86      0.86      0.86       931\n",
      "weighted avg       0.86      0.86      0.86       931\n",
      "\n",
      "0.8592910848549946\n",
      "[[395  80]\n",
      " [ 51 405]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "KNN = KNeighborsClassifier(n_neighbors=2)\n",
    "KNN .fit(X_train, y_train)\n",
    "prediction = KNN .predict(X_test)\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "print(classification_report(y_test, prediction))\n",
    "print(accuracy_score(y_test, prediction))\n",
    "print(confusion_matrix(y_test, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f359a7",
   "metadata": {},
   "source": [
    "# EXtreme Gradient Boosting (XGB) Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "16641022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d76d622b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.94      0.90       475\n",
      "           1       0.93      0.85      0.89       456\n",
      "\n",
      "    accuracy                           0.90       931\n",
      "   macro avg       0.90      0.90      0.90       931\n",
      "weighted avg       0.90      0.90      0.90       931\n",
      "\n",
      "0.8968850698174007\n",
      "[[446  29]\n",
      " [ 67 389]]\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "XGB = XGBClassifier()\n",
    "XGB.fit(X_train, y_train)\n",
    "prediction = XGB.predict(X_test)\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "print(classification_report(y_test, prediction))\n",
    "print(accuracy_score(y_test, prediction))\n",
    "print(confusion_matrix(y_test, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab510f81",
   "metadata": {},
   "source": [
    "# Multi Layer Perceptron (MLP) Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "be0fa17f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.84      0.86       475\n",
      "           1       0.84      0.89      0.86       456\n",
      "\n",
      "    accuracy                           0.86       931\n",
      "   macro avg       0.86      0.86      0.86       931\n",
      "weighted avg       0.86      0.86      0.86       931\n",
      "\n",
      "0.8635875402792696\n",
      "[[400  75]\n",
      " [ 52 404]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "MLP = MLPClassifier(max_iter=1500,activation='relu', learning_rate_init=0.001,shuffle=True,\n",
    "                    learning_rate='constant', beta_1=0.999, beta_2=0.9 , momentum=0.88,\n",
    "                    power_t=0.9, solver='lbfgs', alpha=1e-6, random_state=101)\n",
    "MLP.fit(X_train, y_train)\n",
    "prediction = MLP.predict(X_test)\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "print(classification_report(y_test, prediction))\n",
    "print(accuracy_score(y_test, prediction))\n",
    "print(confusion_matrix(y_test, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0653be31",
   "metadata": {},
   "source": [
    "### ANN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "589eb24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow_addons import losses\n",
    "from sklearn.metrics import confusion_matrix , classification_report\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "64e2b654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training features = (3723, 59)\n",
      "testing features = (3723,)\n",
      "training labels= (931, 59)\n",
      "testing labels = (931,)\n"
     ]
    }
   ],
   "source": [
    "print('training features =',X_train.shape)\n",
    "print('testing features =',y_train.shape)\n",
    "print('training labels=',X_test.shape)\n",
    "print('testing labels =',y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c2120f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "117/117 [==============================] - 1s 2ms/step - loss: 0.6314 - accuracy: 0.6387\n",
      "Epoch 2/150\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.5602 - accuracy: 0.7088\n",
      "Epoch 3/150\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.5387 - accuracy: 0.7271\n",
      "Epoch 4/150\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.5206 - accuracy: 0.7427\n",
      "Epoch 5/150\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.4940 - accuracy: 0.7615\n",
      "Epoch 6/150\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.4703 - accuracy: 0.7690\n",
      "Epoch 7/150\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.7830\n",
      "Epoch 8/150\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.4339 - accuracy: 0.7926\n",
      "Epoch 9/150\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.7972\n",
      "Epoch 10/150\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.4139 - accuracy: 0.8047\n",
      "Epoch 11/150\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.3881 - accuracy: 0.8203\n",
      "Epoch 12/150\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3787 - accuracy: 0.8257\n",
      "Epoch 13/150\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.3667 - accuracy: 0.8340\n",
      "Epoch 14/150\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.3696 - accuracy: 0.8302\n",
      "Epoch 15/150\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.3518 - accuracy: 0.8450\n",
      "Epoch 16/150\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.3423 - accuracy: 0.8512\n",
      "Epoch 17/150\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.3394 - accuracy: 0.8482\n",
      "Epoch 18/150\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.3264 - accuracy: 0.8496\n",
      "Epoch 19/150\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.3215 - accuracy: 0.8576\n",
      "Epoch 20/150\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.3146 - accuracy: 0.8646\n",
      "Epoch 21/150\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.3097 - accuracy: 0.8657\n",
      "Epoch 22/150\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.3009 - accuracy: 0.8695\n",
      "Epoch 23/150\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.2934 - accuracy: 0.8711\n",
      "Epoch 24/150\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.2957 - accuracy: 0.8705\n",
      "Epoch 25/150\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.2832 - accuracy: 0.8770\n",
      "Epoch 26/150\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.2795 - accuracy: 0.8826\n",
      "Epoch 27/150\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.2825 - accuracy: 0.8786\n",
      "Epoch 28/150\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.2861 - accuracy: 0.8746\n",
      "Epoch 29/150\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.2705 - accuracy: 0.8826\n",
      "Epoch 30/150\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.2678 - accuracy: 0.8842\n",
      "Epoch 31/150\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.2520 - accuracy: 0.8966\n",
      "Epoch 32/150\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.2587 - accuracy: 0.8907\n",
      "Epoch 33/150\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.2559 - accuracy: 0.8904\n",
      "Epoch 34/150\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.2515 - accuracy: 0.8987\n",
      "Epoch 35/150\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.2386 - accuracy: 0.9014\n",
      "Epoch 36/150\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.2439 - accuracy: 0.8990\n",
      "Epoch 37/150\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.2370 - accuracy: 0.9012\n",
      "Epoch 38/150\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.2337 - accuracy: 0.9044\n",
      "Epoch 39/150\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.2361 - accuracy: 0.9012\n",
      "Epoch 40/150\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.2286 - accuracy: 0.9041\n",
      "Epoch 41/150\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.2171 - accuracy: 0.9127\n",
      "Epoch 42/150\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.2230 - accuracy: 0.9114\n",
      "Epoch 43/150\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.2131 - accuracy: 0.9124\n",
      "Epoch 44/150\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.2078 - accuracy: 0.9165\n",
      "Epoch 45/150\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.2121 - accuracy: 0.9124\n",
      "Epoch 46/150\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.2105 - accuracy: 0.9157\n",
      "Epoch 47/150\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.2020 - accuracy: 0.9186\n",
      "Epoch 48/150\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.2009 - accuracy: 0.9200\n",
      "Epoch 49/150\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.1896 - accuracy: 0.9248\n",
      "Epoch 50/150\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.1892 - accuracy: 0.9248\n",
      "Epoch 51/150\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.1863 - accuracy: 0.9283\n",
      "Epoch 52/150\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.1822 - accuracy: 0.9299\n",
      "Epoch 53/150\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.1871 - accuracy: 0.9221\n",
      "Epoch 54/150\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.1828 - accuracy: 0.9216\n",
      "Epoch 55/150\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.1815 - accuracy: 0.9307\n",
      "Epoch 56/150\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.1804 - accuracy: 0.9283\n",
      "Epoch 57/150\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.1685 - accuracy: 0.9318\n",
      "Epoch 58/150\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.1852 - accuracy: 0.9221\n",
      "Epoch 59/150\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.1781 - accuracy: 0.9251\n",
      "Epoch 60/150\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.1876 - accuracy: 0.9237\n",
      "Epoch 61/150\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.1684 - accuracy: 0.9347\n",
      "Epoch 62/150\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.1493 - accuracy: 0.9460\n",
      "Epoch 63/150\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.1728 - accuracy: 0.9345\n",
      "Epoch 64/150\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.1510 - accuracy: 0.9439\n",
      "Epoch 65/150\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.1458 - accuracy: 0.9452\n",
      "Epoch 66/150\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.1475 - accuracy: 0.9465\n",
      "Epoch 67/150\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.1466 - accuracy: 0.9441\n",
      "Epoch 68/150\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.1625 - accuracy: 0.9369\n",
      "Epoch 69/150\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.1583 - accuracy: 0.9374\n",
      "Epoch 70/150\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.1360 - accuracy: 0.9514\n",
      "Epoch 71/150\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.1391 - accuracy: 0.9455\n",
      "Epoch 72/150\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.1452 - accuracy: 0.9436\n",
      "Epoch 73/150\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.1370 - accuracy: 0.9492\n",
      "Epoch 74/150\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.1363 - accuracy: 0.9479\n",
      "Epoch 75/150\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.1246 - accuracy: 0.9562\n",
      "Epoch 76/150\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.1319 - accuracy: 0.9500\n",
      "Epoch 77/150\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.1402 - accuracy: 0.9457\n",
      "Epoch 78/150\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.1567 - accuracy: 0.9417\n",
      "Epoch 79/150\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.1315 - accuracy: 0.9535\n",
      "Epoch 80/150\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.1186 - accuracy: 0.9589\n",
      "Epoch 81/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 0s 1ms/step - loss: 0.1180 - accuracy: 0.9578\n",
      "Epoch 82/150\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.1311 - accuracy: 0.9514\n",
      "Epoch 83/150\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.1079 - accuracy: 0.9621\n",
      "Epoch 84/150\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.1189 - accuracy: 0.9584\n",
      "Epoch 85/150\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.1098 - accuracy: 0.9627\n",
      "Epoch 86/150\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.1124 - accuracy: 0.9602\n",
      "Epoch 87/150\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.1192 - accuracy: 0.9533\n",
      "Epoch 88/150\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.1084 - accuracy: 0.9627\n",
      "Epoch 89/150\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.1037 - accuracy: 0.9629\n",
      "Epoch 90/150\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.1164 - accuracy: 0.9594\n",
      "Epoch 91/150\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.1077 - accuracy: 0.9624\n",
      "Epoch 92/150\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.1091 - accuracy: 0.9589\n",
      "Epoch 93/150\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.1080 - accuracy: 0.9576\n",
      "Epoch 94/150\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.1075 - accuracy: 0.9632\n",
      "Epoch 95/150\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.0983 - accuracy: 0.9648\n",
      "Epoch 96/150\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.0880 - accuracy: 0.9715\n",
      "Epoch 97/150\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.0946 - accuracy: 0.9643\n",
      "Epoch 98/150\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.0946 - accuracy: 0.9656\n",
      "Epoch 99/150\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.0913 - accuracy: 0.9670\n",
      "Epoch 100/150\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.0950 - accuracy: 0.9664\n",
      "Epoch 101/150\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.1393 - accuracy: 0.9414\n",
      "Epoch 102/150\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.1008 - accuracy: 0.9629\n",
      "Epoch 103/150\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.0902 - accuracy: 0.9678\n",
      "Epoch 104/150\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.0908 - accuracy: 0.9680\n",
      "Epoch 105/150\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.0873 - accuracy: 0.9691\n",
      "Epoch 106/150\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.0793 - accuracy: 0.9739\n",
      "Epoch 107/150\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.0849 - accuracy: 0.9691\n",
      "Epoch 108/150\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.0865 - accuracy: 0.9688\n",
      "Epoch 109/150\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.0765 - accuracy: 0.9742\n",
      "Epoch 110/150\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.0851 - accuracy: 0.9696\n",
      "Epoch 111/150\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.0925 - accuracy: 0.9659\n",
      "Epoch 112/150\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.0811 - accuracy: 0.9726\n",
      "Epoch 113/150\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.0755 - accuracy: 0.9761\n",
      "Epoch 114/150\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.0687 - accuracy: 0.9764\n",
      "Epoch 115/150\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.0754 - accuracy: 0.9737\n",
      "Epoch 116/150\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.0971 - accuracy: 0.9621\n",
      "Epoch 117/150\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.0730 - accuracy: 0.9761\n",
      "Epoch 118/150\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.0846 - accuracy: 0.9702\n",
      "Epoch 119/150\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.0965 - accuracy: 0.9645\n",
      "Epoch 120/150\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.0874 - accuracy: 0.9654\n",
      "Epoch 121/150\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.0656 - accuracy: 0.9782\n",
      "Epoch 122/150\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.0659 - accuracy: 0.9780\n",
      "Epoch 123/150\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.0671 - accuracy: 0.9780\n",
      "Epoch 124/150\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.0692 - accuracy: 0.9758\n",
      "Epoch 125/150\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.0816 - accuracy: 0.9723\n",
      "Epoch 126/150\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.0664 - accuracy: 0.9790\n",
      "Epoch 127/150\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.0886 - accuracy: 0.9659\n",
      "Epoch 128/150\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.0910 - accuracy: 0.9678\n",
      "Epoch 129/150\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.0688 - accuracy: 0.9761\n",
      "Epoch 130/150\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.0721 - accuracy: 0.9742\n",
      "Epoch 131/150\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.0584 - accuracy: 0.9823\n",
      "Epoch 132/150\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.1055 - accuracy: 0.9619\n",
      "Epoch 133/150\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.0618 - accuracy: 0.9799\n",
      "Epoch 134/150\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.0592 - accuracy: 0.9796\n",
      "Epoch 135/150\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.0615 - accuracy: 0.9769\n",
      "Epoch 136/150\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.0590 - accuracy: 0.9790\n",
      "Epoch 137/150\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.0606 - accuracy: 0.9780\n",
      "Epoch 138/150\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.0525 - accuracy: 0.9820\n",
      "Epoch 139/150\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.0511 - accuracy: 0.9807\n",
      "Epoch 140/150\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.0507 - accuracy: 0.9847\n",
      "Epoch 141/150\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.0517 - accuracy: 0.9842\n",
      "Epoch 142/150\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.0648 - accuracy: 0.9758\n",
      "Epoch 143/150\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.0553 - accuracy: 0.9815\n",
      "Epoch 144/150\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.0621 - accuracy: 0.9790\n",
      "Epoch 145/150\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.0479 - accuracy: 0.9850\n",
      "Epoch 146/150\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.0885 - accuracy: 0.9664\n",
      "Epoch 147/150\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.0507 - accuracy: 0.9842\n",
      "Epoch 148/150\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.0556 - accuracy: 0.9793\n",
      "Epoch 149/150\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.0458 - accuracy: 0.9863\n",
      "Epoch 150/150\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 0.0551 - accuracy: 0.9817\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e803338160>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ANN = keras.Sequential([\n",
    "        keras.layers.Dense(59, input_dim=59, activation='relu'),\n",
    "        keras.layers.Dense(32, activation='relu'),\n",
    "        keras.layers.Dense(16, activation='relu'),\n",
    "        keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "ANN.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "ANN.fit(X_train, y_train, epochs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "beba71fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 0s 1ms/step - loss: 0.0377 - accuracy: 0.9890\n",
      "[0.0376647524535656, 0.988987386226654]\n"
     ]
    }
   ],
   "source": [
    "print(ANN.evaluate(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f1975ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 1ms/step\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.82      0.86       475\n",
      "           1       0.83      0.90      0.86       456\n",
      "\n",
      "    accuracy                           0.86       931\n",
      "   macro avg       0.86      0.86      0.86       931\n",
      "weighted avg       0.86      0.86      0.86       931\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preds = ANN.predict(X_test)\n",
    "y_preds = np.round(y_preds)\n",
    "    \n",
    "print(\"Classification Report: \\n\", classification_report(y_test, y_preds))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a39a176",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
